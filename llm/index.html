<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Jio Digital Human Voice Chat</title>
  <script src="https://esm.run/@mlc-ai/web-llm" type="module"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
      background-color: #f0f0f0;
    }
    .container {
      background-color: white;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
      padding: 20px;
      width: 80%;
      max-width: 800px;
    }
    h1 {
      text-align: center;
      color: #333;
    }
    #chat-container {
      margin-top: 20px;
    }
    #controls {
      display: flex;
      justify-content: center;
      margin-bottom: 20px;
    }
    button {
      background-color: #4CAF50;
      border: none;
      color: white;
      padding: 10px 20px;
      text-align: center;
      text-decoration: none;
      display: inline-block;
      font-size: 16px;
      margin: 4px 2px;
      cursor: pointer;
      border-radius: 5px;
    }
    #configuration {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 20px;
    }
    #model-info {
      font-size: 0.8em;
      color: #666;
    }
    #visualizer {
      height: 100px;
      background-color: #eee;
      margin-bottom: 20px;
    }
    #conversation {
      height: 300px;
      border: 1px solid #ddd;
      overflow-y: auto;
      padding: 10px;
      margin-bottom: 20px;
    }
    #logs {
      height: 100px;
      border: 1px solid #ddd;
      overflow-y: auto;
      padding: 10px;
      font-size: 0.8em;
    }
    .hidden {
      display: none;
    }
    #model-selection {
      margin-right: 10px;
    }
    #chat-box {
      height: 300px;
      border: 1px solid #ddd;
      overflow-y: auto;
      padding: 10px;
      margin-bottom: 20px;
    }
    .message-container {
      margin-bottom: 10px;
    }
    .message {
      padding: 5px 10px;
      border-radius: 5px;
      max-width: 80%;
    }
    .user {
      text-align: right;
    }
    .user .message {
      background-color: #dcf8c6;
      margin-left: auto;
    }
    .assistant .message {
      background-color: #f1f0f0;
    }
    #user-input {
      width: calc(100% - 70px);
      padding: 10px;
      margin-right: 10px;
    }
  </style>
</head>
<body>
<div class="container">
  <h1>Digital Human Voice</h1>
  <div id="chat-container">
    <div id="controls">
      <select id="model-selection"></select>
      <button id="download">Initialize Model</button>
    </div>

    <div id="configuration">
      <div id="model-info">
       LLM: <span id="selected-model"></span>
      </div>
    </div>
    <div id="chat-box"></div>
    <div id="chat-input-container">
      <input type="text" id="user-input" placeholder="Type your message...">
      <button id="send" disabled>Send</button>
    </div>

    <div id="chat-stats" class="hidden"></div>
  </div>

  <h2>Logs</h2>
  <div id="logs">
    <div id="download-status" class="hidden"></div>
  </div>
  <button id="clear-logs">Clear</button>
</div>

<script type="module">
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";

  const messages = [
    {
      content: "You are a helpful AI agent helping users.",
      role: "system"
    }
  ];

  const availableModels = webllm.prebuiltAppConfig.model_list.map(
    (m) => m.model_id
  );
  let selectedModel = "TinyLlama-1.1B-Chat-v0.4-q4f32_1-MLC-1k";

  function updateEngineInitProgressCallback(report) {
    console.log("initialize", report.progress);
    document.getElementById("download-status").textContent = report.text;
  }

  const engine = new webllm.MLCEngine();
  engine.setInitProgressCallback(updateEngineInitProgressCallback);

  async function initializeWebLLMEngine() {
    document.getElementById("download-status").classList.remove("hidden");
    selectedModel = document.getElementById("model-selection").value;
    const config = {
      temperature: 1.0,
      top_p: 1
    };
    await engine.reload(selectedModel, config);
    document.getElementById("selected-model").textContent = selectedModel;
  }

  async function streamingGenerating(messages, onUpdate, onFinish, onError) {
    try {
      let curMessage = "";
      const completion = await engine.chat.completions.create({
        stream: true,
        messages
      });
      for await (const chunk of completion) {
        const curDelta = chunk.choices[0].delta.content;
        if (curDelta) {
          curMessage += curDelta;
        }
        onUpdate(curMessage);
      }
      const finalMessage = await engine.getMessage();
      onFinish(finalMessage);
    } catch (err) {
      onError(err);
    }
  }

  function onMessageSend() {
    const input = document.getElementById("user-input").value.trim();
    const message = {
      content: input,
      role: "user"
    };
    if (input.length === 0) {
      return;
    }
    document.getElementById("send").disabled = true;

    messages.push(message);
    appendMessage(message);

    document.getElementById("user-input").value = "";
    document.getElementById("user-input").setAttribute("placeholder", "Generating...");

    const aiMessage = {
      content: "typing...",
      role: "assistant"
    };
    appendMessage(aiMessage);

    const onFinishGenerating = (finalMessage) => {
      updateLastMessage(finalMessage);
      document.getElementById("send").disabled = false;
      engine.runtimeStatsText().then((statsText) => {
        document.getElementById("chat-stats").classList.remove("hidden");
        document.getElementById("chat-stats").textContent = statsText;
      });
    };

    streamingGenerating(
      messages,
      updateLastMessage,
      onFinishGenerating,
      console.error
    );
  }

  function appendMessage(message) {
    const chatBox = document.getElementById("chat-box");
    const container = document.createElement("div");
    container.classList.add("message-container");
    const newMessage = document.createElement("div");
    newMessage.classList.add("message");
    newMessage.textContent = message.content;

    if (message.role === "user") {
      container.classList.add("user");
    } else {
      container.classList.add("assistant");
    }

    container.appendChild(newMessage);
    chatBox.appendChild(container);
    chatBox.scrollTop = chatBox.scrollHeight;
  }

  function updateLastMessage(content) {
    const messageDoms = document.getElementById("chat-box").querySelectorAll(".message");
    const lastMessageDom = messageDoms[messageDoms.length - 1];
    lastMessageDom.textContent = content;
  }

  availableModels.forEach((modelId) => {
    const option = document.createElement("option");
    option.value = modelId;
    option.textContent = modelId;
    document.getElementById("model-selection").appendChild(option);
  });
  document.getElementById("model-selection").value = selectedModel;
  document.getElementById("download").addEventListener("click", function () {
    initializeWebLLMEngine().then(() => {
      document.getElementById("send").disabled = false;
    });
  });
  document.getElementById("send").addEventListener("click", function () {
    onMessageSend();
  });
  document.getElementById("user-input").addEventListener("keypress", function (e) {
    if (e.key === "Enter") {
      onMessageSend();
    }
  });
  document.getElementById("clear-logs").addEventListener("click", function () {
    document.getElementById("logs").innerHTML = '';
  });
</script>
</body>
</html>
